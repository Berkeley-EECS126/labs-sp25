{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"fountain_codes.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed\n",
    "%pip install -r requirements.txt\n",
    "# Restart kernel if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes for Efficient Transmission of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "When sending packets of data over a communication channel such as the internet or a radio channel, packets often get erased. Because of this, packets must be sent under some erasure code such that the data can still be recovered. In CS 70, you may have learned about an erasure code that involves embedding the data in a polynomial, and then sampling points from that polynomial. There, we assumed that there were at most $k$ erasures in the channel. This week, we'll explore a different channel model in which each packet independently has a probability $p$ of being erased. In particular, this lab will look at random bipartite graphs (the balls and bins model).\n",
    "\n",
    "A little more on the channel and the erasure code; formally, our channel is called the binary erasure channel (BEC), where bits that are sent through a noisy channel either make it through unmodified or are tagged as \"corrupt\", in which case the received information is dropped in all further information processing steps. Here's an image that shows what happens:\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Binary_erasure_channel.svg/156px-Binary_erasure_channel.svg.png\" style=\"background-color: white; padding: 10px\"></center>\n",
    "\n",
    "If we wanted to convey a message, we could consider a feedback channel in which the receiver tells the sender which messages were received and the sender re-sends the dropped packets. This process can be repeated until the receiver gets all of the intended message. While this procedure is indeed optimal in all senses of the word, feedback is simply not possible in many circumstances. If Netflix is trying to stream a show chunked into $n$ data chunks to a million people, its servers can't process all the feedback from the users. Thus, Netflix must use a method independent of feedback. If they use near-optimal codes to encode and constantly send out the same random chunks of the video's data to all users, then they can be sure that users get what they need in only a little more than $n$ transmissions *no matter what parts of the show each individual user lost through their specific channel*!\n",
    "\n",
    "So what's the secret to this magic?  It's a two step process of clever encoding and decoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "1. Suppose your data can be divided into $n$ chunks. First, pick an integer $d$ ($1 \\leq d \\leq n$) according to some distribution.\n",
    "2. With $d$ picked, now select $d$ random chunks of the data and combine their binary representations together using the XOR operator.\n",
    "3. Transmit these chunks, along with the metadata telling which actual chunk indices were XOR'd, as a packet. If a packet is erased, both the chunks it contains and the chunk indices would be lost. \n",
    "\n",
    "### Decoding\n",
    "1. For each packet that has been received, check if it only contains one chunk, in which case the packet is exactly equal to the single chunk it contains. If not, we can check if any of the chunks in the packet are already known, in which case XOR that chunk with the packet and remove it from the list of chunk indices that make up the packet.\n",
    "3. If there are two or more indices in the list left for the packet, we cannot figure out any more information!  Put it on the side for looking at later.\n",
    "4. With any newly decoded information, we may be able to decode previously undecodable packets that we had put on the side.  Go through all unsolved packets and try to decode more packets until nothing more can be done.\n",
    "5. Wait for the next packet to come and repeat!\n",
    "\n",
    "Now what's left for you to do?  Well, remember that number $d$?  It needs to be picked according to some distribution, and which distribution is the million dollar question!\n",
    "\n",
    "\n",
    "### Example\n",
    "<center><img src=\"bipartite.png\" style=\"width: 300px;\"> </center>\n",
    "\n",
    "Consider the above bipartite graph. Here, the right square nodes represent the packets, and the left circular nodes represent the data chunks ($X_i, i=1,..,4$). There is an edge from a packet to a chunk if the packet contains that chunk. Let's try decoding the packets chronologically.\n",
    "1. Since the first packet contains only the third data chunk, we are able to immediately resolve it and find that $X_3=1$.\n",
    "2. The second packet contains the second and third chunks XOR'd together. Since we already know the third chunk, we can XOR the third chunk ($X_3=1$) with the data packet (0) to get the value of the second data chunk, $X_2=1$.\n",
    "3. The third packet contains the XOR of data chunks 1, 2, and 4. We have already determined chunks 2 and 3, so we are able to XOR 2 from this packet, but are still left with 1 and 4, and so must move on.\n",
    "4. With the arrival of the fourth packet, we are able to resolve everything: data chunks 2 and 3 are already determined, and so we are able to XOR chunk 3 ($X_3=1$) with this new data packet (1) to get the value of the chunk 4, $X_4=0$. With this new information, we are able to resolve $X_1$, as packet 3 gave us the equation $1 = X_1 \\oplus X_2 \\oplus X_4 = X_1 \\oplus 1 \\oplus 0$. We can solve this to get $X_1 = 0$.\n",
    "5. We have now solved for all the data chunks, with $X_1 = 0, X_2 = 1, X_3 = 1, X_4 = 0$.\n",
    "\n",
    "As you might be able to tell, by choosing a good degree distribution for $d$, even when random incoming packets were lost (not shown), you were still able to recover all $4$ symbols only from $4$ received packets, despite the sender not knowing what packets you lost through the BEC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import stats\n",
    "\n",
    "rng_seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Implementing the Receiver\n",
    "\n",
    "We've provided you with some starter code, including a `Packet` class, a `Transmitter` class, a `Channel` class, and a `Receiver` class. \n",
    "\n",
    "**Your job is to complete the `receive_packet()` function in the `Receiver` class**. \n",
    "\n",
    "Feel free to write any additional functions that you may need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packet Class & Utility functions\n",
    "\n",
    "A packet consists of...\n",
    "- `chunk_indices`: A list of indices denoting which data chunks are XOR'd together in the packet.\n",
    "- `data`: The XOR'd data chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor(chunks):\n",
    "    \"\"\"\n",
    "    XOR's a collection of chunks, where each chunk is an array.\n",
    "    \"\"\"\n",
    "    tmp = np.zeros(Packet.size_of_packet, 'uint8')\n",
    "    for each_chunk in chunks:\n",
    "        tmp = np.bitwise_xor(tmp, each_chunk)\n",
    "    return tmp\n",
    "\n",
    "class Packet:\n",
    "    size_of_packet = 256\n",
    "    def __init__(self, chunks, chunk_indices):\n",
    "        self.data = xor(chunks)\n",
    "        self.chunk_indices = chunk_indices\n",
    "            \n",
    "    def num_of_chunks(self):\n",
    "        return len(self.chunk_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Class\n",
    "\n",
    "`Channel` class takes a packet and erases it with probability `eps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel:\n",
    "    def __init__(self, eps):\n",
    "        self.eps = eps\n",
    "        self.current_packet = None\n",
    "        \n",
    "    def enqueue(self, packet):\n",
    "        if np.random.random() < self.eps:\n",
    "            self.current_packet = None\n",
    "        else:\n",
    "            self.current_packet = packet\n",
    "            \n",
    "    def dequeue(self):\n",
    "        return self.current_packet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmitter/Encoder Class\n",
    "\n",
    "You can initiate an encoder with a string! Then, `generate_packet()` will return a randomly encoded packet. \n",
    "\n",
    "In our code, the degree $d$ discussed above will be represented by the variable `n_of_chunks`. \n",
    "We'll start by considering a very simple degree distribution, which we will call the `single` distribution: the degree $d$ is always equal to 1. \n",
    "\n",
    "### Task 1.1: \n",
    "Implement the logic when `degree_distribution` is `single`. \n",
    "\n",
    "\n",
    "We will implement other distributions in later tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "class Transmitter:\n",
    "    def __init__(self, chunks, channel, degree_distribution):\n",
    "        self.chunks = chunks\n",
    "        self.num_chunks = len(chunks)\n",
    "        self.channel = channel\n",
    "        self.degree_distribution = degree_distribution\n",
    "        \n",
    "    def generate_new_packet(self, num_sent=None):\n",
    "        \"\"\"\n",
    "        Defines the probability distribution for the number of \n",
    "        chunks sent in each packet. Optionally may use the number\n",
    "        of packets already sent as a parameter.\n",
    "        \"\"\"\n",
    "        if self.degree_distribution == 'single':\n",
    "            # Always give a degree of 1\n",
    "            # TODO: Q1\n",
    "            pass\n",
    "        elif self.degree_distribution == 'double':\n",
    "            # Always give a degree of 2\n",
    "            # TODO: Q2\n",
    "            pass\n",
    "        elif self.degree_distribution == 'uniform':\n",
    "            \"\"\"\n",
    "            Randomly assign a degree from between 1 and 5 (inclusive).\n",
    "            If num_chunks < 5, randomly assign a degree from \n",
    "            between 1 and num_chunks\n",
    "            \"\"\"\n",
    "            # TODO: Q3\n",
    "            pass\n",
    "        elif self.degree_distribution == 'ideal_soliton':\n",
    "            # Ideal Soliton distribution\n",
    "            # TODO: Q3\n",
    "            pass\n",
    "        elif self.degree_distribution == 'competition':\n",
    "            # TODO: Q4\n",
    "            pass\n",
    "            n_of_chunks=1\n",
    "        chunk_indices = list(np.random.randint(self.num_chunks, size=n_of_chunks))\n",
    "        chunks = [ self.chunks[x] for x in chunk_indices ]\n",
    "        return Packet( chunks, chunk_indices )\n",
    "        \n",
    "    def transmit_one_packet(self, num_sent=None):\n",
    "        packet = self.generate_new_packet(num_sent)\n",
    "        self.channel.enqueue( packet )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Receiver/Decoder Class\n",
    "\n",
    "You can initiate a decoder with the total number of chunks. Then, `add_packet()` will add a received packet to the decoder.\n",
    "\n",
    "### Task 1.2\n",
    "Implement the `receive_packet()` function in the `Receiver` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "class Receiver:\n",
    "    def __init__(self, num_chunks, channel):\n",
    "        # Total number of chunks to expect.\n",
    "        self.num_chunks = num_chunks\n",
    "        \n",
    "        # List of packets to process.\n",
    "        self.received_packets = []\n",
    "        \n",
    "        # List of decoded chunks, where self.chunks[i] is the original chunk x_i.\n",
    "        self.chunks = np.zeros((num_chunks, Packet.size_of_packet),dtype=np.uint8)\n",
    "        \n",
    "        # Boolean array to keep track of which packets have been found, where self.found[i] indicates\n",
    "        # if x_i has been found.\n",
    "        self.found = [ False for x in range(self.num_chunks) ]\n",
    "        self.channel = channel\n",
    "        \n",
    "    def receive_packet(self):\n",
    "        \"\"\"\n",
    "        Processes a new packet and peels off known chunks. \n",
    "        Adds the packet to the list of received packets and \n",
    "        does extra processing if the packet has a single chunk.\n",
    "        \"\"\"\n",
    "        packet = self.channel.dequeue()\n",
    "        if packet is not None:\n",
    "            ...\n",
    "    \n",
    "    def peeling(self):\n",
    "        \"\"\"\n",
    "        Recommended helper function to process the packets if there\n",
    "        exists a packet with a single chunk.\n",
    "        \"\"\"\n",
    "        ...\n",
    "    \n",
    "    def isDone(self):\n",
    "        return self.chunksDone() == self.num_chunks\n",
    "\n",
    "    def chunksDone(self):\n",
    "        return sum(self.found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Sending the raccoon\n",
    "We'll now use the `Transmitter` and `Receiver` classes to send a grayscale image over a noisy channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array(plt.imread(\"raccoon.jpg\"))\n",
    "# converts the image to grayscale\n",
    "x = np.sum(l * (0.299, 0.587, 0.113), axis=-1)\n",
    "x = np.array(x, dtype=np.uint8)\n",
    "\n",
    "plt.imshow(x, cmap = cm.Greys_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1\n",
    "\n",
    "Break up the image shown below into $1024$ chunks of size $256$ each.\n",
    "\n",
    "*Hint:* You should only need one line for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "image_data = x[:, :]\n",
    "size_of_packet = 256 \n",
    "num_of_packets = 1024\n",
    "assert np.prod(image_data.shape) == size_of_packet * num_of_packets\n",
    "\n",
    "chunks = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Returns a tuple (packets sent, intermediate image every 512 packets + final image, chunks decoded every 64 packets)\n",
    "def send(tx, rx, verbose=False):\n",
    "    \"\"\"\n",
    "    Repeatedly sends packets from the transmitter to the \n",
    "    receiver until all chunks have been decoded or\n",
    "    the maximum threshold has been reached.\n",
    "    \"\"\"\n",
    "    threshold = rx.num_chunks * 20\n",
    "    num_sent = 0\n",
    "    images = []\n",
    "    chunks_decoded = []\n",
    "    while not rx.isDone():\n",
    "        tx.transmit_one_packet(num_sent)\n",
    "        rx.receive_packet()\n",
    "        if num_sent % 512 == 0:\n",
    "            images.append(np.array(rx.chunks.reshape((512,512))))\n",
    "            if verbose:\n",
    "                print(num_sent, rx.chunksDone())\n",
    "        if num_sent % 64 == 0:\n",
    "            chunks_decoded.append(rx.chunksDone())\n",
    "        num_sent += 1\n",
    "        if num_sent > threshold:\n",
    "            print(\"Ending transmission because too many packets have been sent. This may be caused by a bug in \" + \n",
    "                  \"receive_packet or an inefficient custom strategy.\")\n",
    "            break\n",
    "            \n",
    "    chunks_decoded.append(rx.chunksDone())\n",
    "    images.append(rx.chunks.reshape((512,512)))\n",
    "    return (num_sent, images, chunks_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the `single` degree distribution defined in the `Transmitter` class, send the raccoon over a channel with erasure probability 0.2.\n",
    "\n",
    "How many packets did you need to send?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the below values to setup the channel\n",
    "eps = 0.2\n",
    "ch = Channel(eps)\n",
    "tx = Transmitter(chunks, ch, 'single')\n",
    "rx = Receiver(len(chunks), ch)\n",
    "\n",
    "single_sent, images, single_decoded = send(tx,rx)\n",
    "\n",
    "print(\"The number of packets sent: {}\".format(single_sent))\n",
    "\n",
    "n_of_figures = len(images)\n",
    "fig = plt.figure(figsize=(8, 3*n_of_figures))\n",
    "\n",
    "for i in range(n_of_figures):\n",
    "    fig.add_subplot(n_of_figures,1,i+1)\n",
    "    plt.imshow(images[i], cmap = cm.Greys_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Task 2.2 (manually graded)\n",
    "\n",
    "Plot the number of chunks decoded as a function of the number of packets you send.\n",
    "The `chunks_decoded` array should be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "num_chunks_decoded = ...\n",
    "num_packets_sent = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Task 2.3 (manually graded)\n",
    "Looking at the graph, we see that it gets harder and harder to find the rest as we decode more and more chunks. Does this remind you of a well known theoretical problem? Which problem is it?\n",
    "\n",
    "*Hint:* Try out some small examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Task 2.4\n",
    "Implement the `double` degree distribution in the `Transmitter` class. This distribution will always set the degree $d$ to 2.\n",
    "\n",
    "Then, run the cell below to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Task 2.5 (manually graded)\n",
    "In the cell below, try to send the raccoon over a channel with erasure probability 0.2 using the `double` degree distribution (don't worry about intermediate plots this time). \n",
    "\n",
    "Comment on what happens when you try the `double` degree distribution. Can you tell why this happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q3. Randomized Distributions\n",
    "You have seen two degree distributions so far.  Both of these have been deterministic, and one worked better than the other.  Let's try a different degree distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Task 3.1 (manually graded)\n",
    "Implement the `uniform` degree distribution in the `Transmitter` class. \n",
    "The `uniform` degree distribution will randomly pick a degree $d$ uniformly at random from $1$ to $5$\n",
    "(why might it be a good idea to limit the degree to 5?). If we have fewer than $5$ chunks, we will instead pick $d$ uniformly at random from $1$ to the number of chunks.\n",
    "\n",
    "\n",
    "Next, use the `uniform` degree distribution to send the raccoon over a channel with erasure probability 0.2 over multiple trials. \n",
    "For each trial, record the number of packets sent for the image to be decoded. Then, plot this as a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "num_trials = 100  # do not change this\n",
    "eps = 0.2\n",
    "ch = Channel(eps)\n",
    "tx = Transmitter(chunks, ch, 'uniform')\n",
    "\n",
    "packets_required = []\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    rx = Receiver(0, None) # TODO: set appropriate values here\n",
    "    ...\n",
    "    \n",
    "    \n",
    "# Plot the packets required as a histogram\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You can run the cell below to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Task 3.2\n",
    "Let's examine one final degree distribution. \n",
    "The **ideal soliton distribution** is defined as follows:\n",
    "$$\\rho(d) = \n",
    "\\begin{cases}\n",
    "\\frac{1}{n} & d = 1 \\\\\n",
    "\\frac{1}{d(d-1)} &d = 2,3,...,n\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This distribution has the nice property that at each decoding step, we can decode 1 new symbol in expectation. Therefore, we might expect to decode the message fully after $n$ decoding steps (in contrast, how many steps would we expect to need with the `single` distribution?).\n",
    "\n",
    "Implement the `ideal_soliton` degree distribution in the `Transmitter` class. \n",
    "\n",
    "*Hint:* As we saw in homework, we can sample from any distribution by sampling a uniform random variable and then applying an inverse CDF. \n",
    "\n",
    "*Hint 2*: Can you derive a relatively simple closed form for the ideal soliton CDF? Perform partial fraction decomposition on each term of the PMF and see if you can cancel out terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You can run the cell below to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Task 3.3 (manually graded)\n",
    "Using the `ideal_soliton` degree distribution, send the image over a channel with erasure probability 0.2. Plot the number of packets decoded against the number of packets transmitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "eps = 0.2\n",
    "ch = Channel(eps)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Optional: Competition Model\n",
    "\n",
    "Suppose your friend Alice finished her EECS 126 homework early for once and plans to sit down for a movie night (she wants to make use of the 30-day free trial of Netflix!). While Alice is surfing Netflix she decides she wants to stream Interstellar. Alice's laptop drops packets with $p=0.2$. You, the Chief Technology Officer of Netflix, know that given the heavy workload of EECS 126, this may be your only chance to convert this freeloading customer into a permanent one, but to do so you're going to have to make sure her viewing experience is perfect.\n",
    "\n",
    "### Task 4 (Optional)\n",
    "Implement the `competition` degree distribution in the `Transmitter` class according to the following rules:\n",
    "\n",
    "### Concrete specs:\n",
    "\n",
    "- You are given an erasure channel with drop probability $p=0.2$.\n",
    "- You must define a degree distribution (which can vary as a function of the # of transmissions already sent) to minimize the number of total packets needed to be sent for the raccoon to be decoded.  Run your code for 100 trials to get a good estimate of the true number of transmissions needed per image while they watch their movies.  Each trial, your score is \n",
    "\n",
    "<!-- $$\\frac{\\text{\\# of packets successfully decoded from the first 512 packets}}{512}+\\frac{\\text{\\# of packets successfully decoded from the first 1024 packets}}{1024}+\\lfloor\\frac{\\text{\\# of packets successfully decoded from the first 2048 packets}}{1024}\\rfloor+\\lfloor\\frac{\\text{\\# of packets successfully decoded from the first 4096 packets}}{1024}\\rfloor+\\lfloor\\frac{\\text{\\# of packets successfully decoded from the first 6144 packets}}{1024}\\rfloor$$ -->\n",
    "\n",
    "$$\\sum_{n = \\{512, 1024\\}} \\frac{S(n)}{n} + \\sum_{n = \\{2048, 4096\\}}\\left\\lfloor \\frac{S(n)}{n}\\right\\rfloor$$\n",
    "\n",
    "where\n",
    "\n",
    "$$S(n) = \\text{\\# of chunks successfully decoded from the first } n \\text{ packets}$$\n",
    "\n",
    "- Note the floor function in the later stages - you can only get the point if you fully decode the file with the alloted number of packets.\n",
    "- Aim to get a score of at least 3. \n",
    "- Hint: most distributions will not be able to score more than 3. See if you can take advantage of properties of the Fountain Code algorithm using the `num_sent` argument of `Transmitter`.\n",
    "\n",
    "\n",
    "Good luck! \n",
    "\n",
    "<!-- *Note that we will be rerunning solutions, so do not cheat.* -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(chunks_decoded):\n",
    "    c_d = chunks_decoded\n",
    "    s = c_d[8]/512+c_d[16]/1024\n",
    "    arr = [33,65,97]\n",
    "    for i in arr:\n",
    "        if i >= len(c_d):\n",
    "            s += 1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Test your implementation here!\n",
    "eps = 0.2\n",
    "ch = Channel(eps)\n",
    "tx = Transmitter(chunks, ch, 'competition')\n",
    "rx = Receiver(len(chunks), ch)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following code to score your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.2\n",
    "ch = Channel(eps)\n",
    "\n",
    "s_log = []\n",
    "s = 0\n",
    "avg = 0\n",
    "trials = 100\n",
    "for i in range(trials):\n",
    "    tx_competition = Transmitter(chunks, ch, 'competition')\n",
    "    rx = Receiver(len(chunks), ch)\n",
    "    comp_sent, images, comp_decoded = send(tx_competition,rx)\n",
    "    s_log.append(s)\n",
    "    s += score(comp_decoded)\n",
    "    avg += comp_sent\n",
    "print(\"Score: {}\".format(s/trials))\n",
    "print(\"Sent: {}\".format(avg/trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Further Reading\n",
    "[1] D. Mackay.  Information Theory, Inference, and Learning Algorithms. 2003 \n",
    "\n",
    "[2] D. Mackay. Fountain Codes. 2005. https://docs.switzernet.com/people/emin-gabrielyan/060112-capillary-references/ref/MacKay05.pdf\n",
    "\n",
    "[3] M. Luby. LT Codes. 2002. https://pages.cs.wisc.edu/~suman/courses/740/papers/luby02lt.pdf\n",
    "\n",
    "[4] http://blog.notdot.net/2012/01/Damn-Cool-Algorithms-Fountain-Codes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "This lab will be partially autograded and partially manually (self) graded. This time, you need to submit to **two** Gradescope assignments. Please ensure you submit the ipython notebook (or exported zip file) to the appropriate Gradescope assignment **and** upload a PDF of your lab to the corresponding (separate) Gradescope assignment. \n",
    "\n",
    "The export cell will generate a PDF with unnecessary sections filtered out; this is OK as long as all responses and graphs for the manually-graded tasks are visible. If the export cell does not work for you, you may also export the notebook to PDF using a different method and select the appropriate pages on Gradescope. \n",
    "\n",
    "**Double-check to ensure that both files are submitted correctly, and ensure any plots we ask you to make are visible in your PDF submission.** We will not give extensions or accommodations for submissions that do not follow these instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "eecs126",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "fountain_codes",
   "tests": {
    "q1": {
     "name": "q1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_single():\n...     eps = 0\n...     channel = Channel(eps)\n...     rng = np.random.default_rng(rng_seed)\n...     chunks = rng.integers(0, 2, (10, Packet.size_of_packet), dtype=np.uint8)\n...     tx = Transmitter(chunks, channel, 'single')\n...     for i in range(10):\n...         pkt = tx.generate_new_packet()\n...         assert pkt.num_of_chunks() == 1, 'Single degree distribution generated packet with more than 1 chunk'\n>>> test_single()\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def test_send_recv():\n...     eps = 0\n...     channel = Channel(eps)\n...     rng = np.random.default_rng(rng_seed)\n...     chunks = rng.integers(0, 2, (10, Packet.size_of_packet), dtype=np.uint8)\n...     tx = Transmitter(chunks, channel, 'single')\n...     rx = Receiver(len(chunks), channel)\n...     max_iter = 100\n...     iter = 0\n...     while not rx.isDone():\n...         tx.transmit_one_packet()\n...         rx.receive_packet()\n...         iter += 1\n...         if iter > max_iter:\n...             break\n...     assert np.array_equal(rx.chunks, chunks), 'Reconstructed chunks do not match original chunks'\n>>> test_send_recv()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(chunks) == num_of_packets, f'Image should be divided into {num_of_packets} chunks'\n>>> assert len(chunks[0]) == size_of_packet, f'Each chunk should have size {size_of_packet}'\n>>> def test_chunks():\n...     ch = Channel(0)\n...     tx = Transmitter(chunks, ch, 'single')\n...     rx = Receiver(num_of_packets, ch)\n...     num_sent, images, chunks_decoded = send(tx, rx)\n...     assert np.array_equal(images[-1], image_data), 'Failed to reconstruct image from chunks'\n>>> test_chunks()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.4": {
     "name": "q2.4",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_double():\n...     eps = 0\n...     channel = Channel(eps)\n...     rng = np.random.default_rng(rng_seed)\n...     chunks = rng.integers(0, 2, (10, Packet.size_of_packet), dtype=np.uint8)\n...     tx = Transmitter(chunks, channel, 'double')\n...     for i in range(10):\n...         pkt = tx.generate_new_packet()\n...         assert pkt.num_of_chunks() == 2, 'Double degree distribution generated packet with more than 2 chunks'\n>>> test_double()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.1": {
     "name": "q3.1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_uniform():\n...     from collections import Counter\n...     eps = 0\n...     channel = Channel(eps)\n...     rng = np.random.default_rng(rng_seed)\n...     chunks1 = rng.integers(0, 2, (3, Packet.size_of_packet), dtype=np.uint8)\n...     tx1 = Transmitter(chunks1, channel, 'uniform')\n...     c1 = Counter()\n...     n_trials = 1500\n...     for _ in range(n_trials):\n...         pkt = tx1.generate_new_packet()\n...         c1[pkt.num_of_chunks()] += 1\n...     try:\n...         res1 = stats.chisquare(list(c1.values()), list(np.ones(3) * n_trials / 3))\n...     except ValueError:\n...         assert False, 'Uniform degree distribution not generating packets over the correct range'\n...     assert res1.pvalue > 0.05, 'Uniform degree distribution is not generating packets uniformly'\n...     chunks2 = rng.integers(0, 2, (10, Packet.size_of_packet), dtype=np.uint8)\n...     tx2 = Transmitter(chunks2, channel, 'uniform')\n...     c2 = Counter()\n...     for _ in range(n_trials):\n...         pkt = tx2.generate_new_packet()\n...         c2[pkt.num_of_chunks()] += 1\n...     try:\n...         res2 = stats.chisquare(list(c2.values()), list(np.ones(5) * n_trials / 5))\n...     except ValueError:\n...         assert False, 'Uniform degree distribution not generating packets over the correct range'\n...     assert res2.pvalue > 0.05, 'Uniform degree distribution is not generating packets uniformly'\n>>> test_uniform()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.2": {
     "name": "q3.2",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_sd():\n...     from collections import Counter\n...     eps = 0\n...     channel = Channel(eps)\n...     rng = np.random.default_rng(rng_seed)\n...     n_packets = 10\n...     chunks1 = rng.integers(0, 2, (n_packets, Packet.size_of_packet), dtype=np.uint8)\n...     tx1 = Transmitter(chunks1, channel, 'ideal_soliton')\n...     c1 = Counter()\n...     n_trials = 1500\n...     for _ in range(n_trials):\n...         pkt = tx1.generate_new_packet()\n...         c1[pkt.num_of_chunks()] += 1\n...     empirical_counts = [c1[k] for k in range(1, n_packets + 1)]\n...     expected_counts = [n_trials / n_packets] + [n_trials / (k * (k - 1)) for k in range(2, n_packets + 1)]\n...     try:\n...         res1 = stats.chisquare(empirical_counts, expected_counts)\n...     except ValueError:\n...         assert False, 'Ideal Soliton degree distribution not generating packets over the correct range'\n...     assert res1.pvalue > 0.05, 'Ideal Soliton degree distribution is not generating packets according to the ideal soliton distribution'\n>>> test_sd()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
